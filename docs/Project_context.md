# ğŸ“˜ Project Context â€” LexiSense Hackathon

This file documents the **tools, approach, and important decisions** for the LexiSense project.  
It is meant to serve as a reference for future developers (or an LLM) so the project context is always clear.

---

## ğŸ”¹ Project Overview
- **Problem Statement ID:** 25035  
- **Title:** Sentiment analysis of comments received through E-consultation module  
- **Organization:** Ministry of Corporate Affairs (MoCA)  
- **Goal:** Analyze stakeholder feedback on draft legislations to help policymakers understand public opinion faster.  

---

## ğŸ”¹ Approach
1. **Input**  
   - Stakeholders submit comments (text or CSV for demo).  

2. **Processing (via AI pipelines)**  
   - **Sentiment Analysis:** Classify comments as Positive / Negative / Neutral.  
   - **Summarization:** Generate short summaries of longer comments.  
   - **Word Cloud:** Visualize frequent keywords across all comments.  

3. **Output (via Streamlit dashboard)**  
   - Interactive interface with:  
     - Single comment analysis  
     - Bulk CSV upload + analysis  
     - Word cloud visualization  
     - Sentiment distribution charts  

---

## ğŸ”¹ Tools & Libraries
### ğŸ§  Machine Learning (Hugging Face Pipelines)
- **Transformers Library:** [https://huggingface.co/docs/transformers](https://huggingface.co/docs/transformers)  
- **Pipelines used:**
  - `sentiment-analysis` â†’ Sentiment classification  
  - `summarization` â†’ Comment summarization  

### ğŸ¨ Visualization
- **Streamlit** (UI + dashboard) â†’ [https://docs.streamlit.io](https://docs.streamlit.io)  
- **WordCloud** (keyword visualization) â†’ [https://amueller.github.io/word_cloud/](https://amueller.github.io/word_cloud/)  
- **Matplotlib** (basic plots for sentiment distribution)  

### ğŸ“‚ Data Handling
- **CSV files** with Pandas for reading/writing.  
- Example: `sample_comments.csv` â†’ analyzed â†’ `processed.csv`  

---

## ğŸ”¹ Architecture (Simplified)
User Comment(s)â†“Streamlit Frontend (UI)â†“Hugging Face Pipelinesâ”œâ”€â”€ Sentiment Analysisâ”œâ”€â”€ Summarizationâ””â”€â”€ Word Cloudâ†“Dashboard Output (tables, charts, images)


---

## ğŸ”¹ Decisions Taken
- âœ… Use **Streamlit** instead of React/FastAPI for simplicity and speed.  
- âœ… Use **Hugging Face pipelines** (pretrained models) â†’ no training required.  
- âœ… Use **CSV files** for storage instead of a database.  
- âœ… Run models **locally** â†’ free, offline after first download.  
- âŒ Dropped old laptop server idea (too complex networking).  
- âœ… Deployment option: **Streamlit Cloud (free)** for public demo URL.  

---

## ğŸ”¹ Future Improvements
- Use **FastAPI + database** (e.g., PostgreSQL) for production scale.  
- Add **aspect-based sentiment** (per clause/section of legislation).  
- Deploy on **cloud VM** for reliability (AWS/GCP).  
- Add **multi-language support** (comments in Hindi/regional languages).  
- Improve **summarization accuracy** with fine-tuned models.  

---

## ğŸ”¹ Team Distribution (6 Members)
- Person 1 â†’ Team Lead / Integrator  
- Person 2 â†’ Streamlit UI  
- Person 3 â†’ Sentiment Analysis  
- Person 4 â†’ Summarization  
- Person 5 â†’ Word Cloud & Charts  
- Person 6 â†’ Backend Testing & Optimizations  

---

## ğŸ”¹ Hackathon Timeline
- **Day 1:** Setup, test Hugging Face pipelines, prepare sample CSVs.  
- **Day 2:** Build Streamlit dashboard, integrate ML functions, add visualizations.  
- **Day 3:** Testing, UI polish, final demo prep.  

---

## ğŸ”¹ Key Takeaways
- Hugging Face pipelines are **ideal for hackathons** â†’ plug-and-play AI.  
- Streamlit makes **professional dashboards fast**.  
- Focus on **polish + working demo** over complex backend.  
- Keep everything **offline-capable** to avoid internet issues in demo.  
